{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Winning Football Team\n",
    "\n",
    "Can we design a predictive model capable of accurately predicting if the home team will win a football match? \n",
    "\n",
    "![alt text](https://6544-presscdn-0-22-pagely.netdna-ssl.com/wp-content/uploads/2017/04/English-Premier-League.jpg \"Logo Title Text 1\")\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. We will clean our dataset\n",
    "2. Split it into training and testing data (12 features & 1 target (winning team (Home/Away/Draw))\n",
    "3. Train 3 different classifiers on the data \n",
    "  -Logistic Regression\n",
    "  -Support Vector Machine \n",
    "  -XGBoost\n",
    "4. Use the best Classifer to predict who will win given an away team and a home team\n",
    "\n",
    "## History\n",
    "\n",
    "Sports betting is a 500 billion dollar market (Sydney Herald)\n",
    "\n",
    "![alt text](https://static1.squarespace.com/static/506a95bbc4aa0491a951c141/t/51a55d97e4b00f4428967e64/1369791896526/sports-620x349.jpg \"Logo Title Text 1\")\n",
    "\n",
    "Kaggle hosts a yearly competiton called March Madness \n",
    "\n",
    "https://www.kaggle.com/c/march-machine-learning-mania-2017/kernels\n",
    "\n",
    "Several Papers on this \n",
    "\n",
    "https://arxiv.org/pdf/1511.05837.pdf\n",
    "\n",
    "\"It is possible to predict the winner of English county twenty twenty cricket games in almost two thirds of instances.\"\n",
    "\n",
    "https://arxiv.org/pdf/1411.1243.pdf\n",
    "\n",
    "\"Something that becomes clear from the results is that Twitter contains enough information to be useful for\n",
    "predicting outcomes in the Premier League\"\n",
    "\n",
    "https://qz.com/233830/world-cup-germany-argentina-predictions-microsoft/\n",
    "\n",
    "For the 2014 World Cup, Bing correctly predicted the outcomes for all of the 15 games in the knockout round.\n",
    "\n",
    "So the right questions to ask are\n",
    "\n",
    "-What model should we use?\n",
    "-What are the features (the aspects of a game) that matter the most to predicting a team win? Does being the home team give a team the advantage? \n",
    "\n",
    "## Dataset\n",
    "\n",
    "- Football is played by 250 million players in over 200 countries (most popular sport globally)\n",
    "- The English Premier League is the most popular domestic team in the world\n",
    "- Retrived dataset from http://football-data.co.uk/data.php\n",
    "\n",
    "![alt text](http://i.imgur.com/YRIctyo.png \"Logo Title Text 1\")\n",
    "\n",
    "- Football is a team sport, a cheering crowd helps morale\n",
    "- Familarity with pitch and weather conditions helps\n",
    "- No need to travel (less fatigue)\n",
    "\n",
    "Acrononyms- https://rstudio-pubs-static.s3.amazonaws.com/179121_70eb412bbe6c4a55837f2439e5ae6d4e.html\n",
    "\n",
    "## Other repositories\n",
    "\n",
    "- https://github.com/rsibi/epl-prediction-2017 (EPL prediction)\n",
    "- https://github.com/adeshpande3/March-Madness-2017 (NCAA prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "import pandas as pd\n",
    "#produces a prediction model in the form of an ensemble of weak prediction models, typically decision tree\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA #for principal component analysis\n",
    "\n",
    "\n",
    "#THESE ARE THE MODELS WE WILL BE TRYING OUT\n",
    "\n",
    "import xgboost as xgb #XGBoost\n",
    "#the outcome (dependent variable) has only a limited number of possible values. \n",
    "#Logistic Regression is used when response variable is categorical in nature.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#A random forest is a meta estimator that fits a number of decision tree classifiers \n",
    "#on various sub-samples of the dataset and use averaging to improve the predictive \n",
    "#accuracy and control over-fitting.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#a discriminative classifier formally defined by a separating hyperplane.\n",
    "from sklearn.svm import SVC #SVM\n",
    "from sklearn import neighbors, datasets #K nearest neighbors\n",
    "from sklearn.ensemble import AdaBoostClassifier #Adaboost\n",
    "from sklearn.naive_bayes import GaussianNB #naive bayes\n",
    "from sklearn import tree #decision tree\n",
    "from sklearn.neural_network import MLPClassifier #multy layer perception (vanilla) neural network\n",
    "\n",
    "#displayd data\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWAY</th>\n",
       "      <th>HOME</th>\n",
       "      <th>HOME_TEAM_RESULT</th>\n",
       "      <th>W%</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>ERA</th>\n",
       "      <th>K%</th>\n",
       "      <th>K%.1</th>\n",
       "      <th>AVG</th>\n",
       "      <th>SLG</th>\n",
       "      <th>W%.1</th>\n",
       "      <th>BABIP.1</th>\n",
       "      <th>ERA.1</th>\n",
       "      <th>K%.2</th>\n",
       "      <th>K%.3</th>\n",
       "      <th>AVG.1</th>\n",
       "      <th>SLG.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orioles</td>\n",
       "      <td>Braves</td>\n",
       "      <td>D</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.299</td>\n",
       "      <td>4.22</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.293</td>\n",
       "      <td>4.51</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates</td>\n",
       "      <td>Tigers</td>\n",
       "      <td>L</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.306</td>\n",
       "      <td>4.22</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.534161</td>\n",
       "      <td>0.300</td>\n",
       "      <td>4.24</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlueJays</td>\n",
       "      <td>Phillies</td>\n",
       "      <td>L</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.282</td>\n",
       "      <td>3.79</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.304</td>\n",
       "      <td>4.64</td>\n",
       "      <td>21.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reds</td>\n",
       "      <td>Indians</td>\n",
       "      <td>L</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.290</td>\n",
       "      <td>4.91</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.583851</td>\n",
       "      <td>0.289</td>\n",
       "      <td>3.86</td>\n",
       "      <td>23.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Braves</td>\n",
       "      <td>Orioles</td>\n",
       "      <td>L</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.293</td>\n",
       "      <td>4.51</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.299</td>\n",
       "      <td>4.22</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AWAY      HOME HOME_TEAM_RESULT        W%  BABIP   ERA    K%  K%.1  \\\n",
       "0   Orioles    Braves                D  0.549383  0.299  4.22  20.4  21.7   \n",
       "1   Pirates    Tigers                L  0.481481  0.306  4.22  19.6  21.3   \n",
       "2  BlueJays  Phillies                L  0.549383  0.282  3.79  21.5  21.9   \n",
       "3      Reds   Indians                L  0.419753  0.290  4.91  19.6  21.1   \n",
       "4    Braves   Orioles                L  0.422360  0.293  4.51  19.6  20.0   \n",
       "\n",
       "     AVG    SLG      W%.1  BABIP.1  ERA.1  K%.2  K%.3  AVG.1  SLG.1  \n",
       "0  0.256  0.443  0.422360    0.293   4.51  19.6  20.0  0.255  0.384  \n",
       "1  0.257  0.402  0.534161    0.300   4.24  20.4  21.3  0.267  0.438  \n",
       "2  0.248  0.426  0.438272    0.304   4.64  21.1  23.0  0.240  0.385  \n",
       "3  0.256  0.408  0.583851    0.289   3.86  23.2  20.2  0.262  0.430  \n",
       "4  0.255  0.384  0.549383    0.299   4.22  20.4  21.7  0.256  0.443  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWAY</th>\n",
       "      <th>HOME</th>\n",
       "      <th>HOME_TEAM_RESULT</th>\n",
       "      <th>W%</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>ERA</th>\n",
       "      <th>K%</th>\n",
       "      <th>K%.1</th>\n",
       "      <th>AVG</th>\n",
       "      <th>SLG</th>\n",
       "      <th>...</th>\n",
       "      <th>B_index</th>\n",
       "      <th>W%.1</th>\n",
       "      <th>BABIP.1</th>\n",
       "      <th>ERA.1</th>\n",
       "      <th>K%.2</th>\n",
       "      <th>K%.3</th>\n",
       "      <th>AVG.1</th>\n",
       "      <th>SLG.1</th>\n",
       "      <th>P_Index.1</th>\n",
       "      <th>B_index.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orioles</td>\n",
       "      <td>Braves</td>\n",
       "      <td>D</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.299</td>\n",
       "      <td>4.22</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.443</td>\n",
       "      <td>...</td>\n",
       "      <td>47.3</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.293</td>\n",
       "      <td>4.51</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.384</td>\n",
       "      <td>24.11</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates</td>\n",
       "      <td>Tigers</td>\n",
       "      <td>L</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.306</td>\n",
       "      <td>4.22</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.402</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.534161</td>\n",
       "      <td>0.300</td>\n",
       "      <td>4.24</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.438</td>\n",
       "      <td>24.64</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlueJays</td>\n",
       "      <td>Phillies</td>\n",
       "      <td>L</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.282</td>\n",
       "      <td>3.79</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.304</td>\n",
       "      <td>4.64</td>\n",
       "      <td>21.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.385</td>\n",
       "      <td>25.74</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reds</td>\n",
       "      <td>Indians</td>\n",
       "      <td>L</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.290</td>\n",
       "      <td>4.91</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.408</td>\n",
       "      <td>...</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.583851</td>\n",
       "      <td>0.289</td>\n",
       "      <td>3.86</td>\n",
       "      <td>23.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.430</td>\n",
       "      <td>27.06</td>\n",
       "      <td>46.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Braves</td>\n",
       "      <td>Orioles</td>\n",
       "      <td>L</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.293</td>\n",
       "      <td>4.51</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.384</td>\n",
       "      <td>...</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.299</td>\n",
       "      <td>4.22</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.443</td>\n",
       "      <td>24.62</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AWAY      HOME HOME_TEAM_RESULT        W%  BABIP   ERA    K%  K%.1  \\\n",
       "0   Orioles    Braves                D  0.549383  0.299  4.22  20.4  21.7   \n",
       "1   Pirates    Tigers                L  0.481481  0.306  4.22  19.6  21.3   \n",
       "2  BlueJays  Phillies                L  0.549383  0.282  3.79  21.5  21.9   \n",
       "3      Reds   Indians                L  0.419753  0.290  4.91  19.6  21.1   \n",
       "4    Braves   Orioles                L  0.422360  0.293  4.51  19.6  20.0   \n",
       "\n",
       "     AVG    SLG    ...      B_index      W%.1  BABIP.1  ERA.1  K%.2  K%.3  \\\n",
       "0  0.256  0.443    ...         47.3  0.422360    0.293   4.51  19.6  20.0   \n",
       "1  0.257  0.402    ...         47.0  0.534161    0.300   4.24  20.4  21.3   \n",
       "2  0.248  0.426    ...         46.7  0.438272    0.304   4.64  21.1  23.0   \n",
       "3  0.256  0.408    ...         46.7  0.583851    0.289   3.86  23.2  20.2   \n",
       "4  0.255  0.384    ...         45.5  0.549383    0.299   4.22  20.4  21.7   \n",
       "\n",
       "   AVG.1  SLG.1  P_Index.1  B_index.1  \n",
       "0  0.255  0.384      24.11       45.5  \n",
       "1  0.267  0.438      24.64       48.0  \n",
       "2  0.240  0.385      25.74       47.0  \n",
       "3  0.262  0.430      27.06       46.4  \n",
       "4  0.256  0.443      24.62       47.3  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWAY</th>\n",
       "      <th>HOME</th>\n",
       "      <th>HOME_TEAM_RESULT</th>\n",
       "      <th>W%</th>\n",
       "      <th>B_index</th>\n",
       "      <th>LV2</th>\n",
       "      <th>wOBA</th>\n",
       "      <th>W%.1</th>\n",
       "      <th>B_index.1</th>\n",
       "      <th>LV2.1</th>\n",
       "      <th>wOBA.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orioles</td>\n",
       "      <td>Braves</td>\n",
       "      <td>D</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>47.3</td>\n",
       "      <td>26.91</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>45.5</td>\n",
       "      <td>26.35</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates</td>\n",
       "      <td>Tigers</td>\n",
       "      <td>L</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>47.0</td>\n",
       "      <td>26.13</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.534161</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27.31</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlueJays</td>\n",
       "      <td>Phillies</td>\n",
       "      <td>L</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>46.7</td>\n",
       "      <td>28.14</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>47.0</td>\n",
       "      <td>28.53</td>\n",
       "      <td>0.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reds</td>\n",
       "      <td>Indians</td>\n",
       "      <td>L</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>46.7</td>\n",
       "      <td>26.46</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.583851</td>\n",
       "      <td>46.4</td>\n",
       "      <td>30.09</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Braves</td>\n",
       "      <td>Orioles</td>\n",
       "      <td>L</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>45.5</td>\n",
       "      <td>26.35</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>47.3</td>\n",
       "      <td>26.91</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AWAY      HOME HOME_TEAM_RESULT        W%  B_index    LV2   wOBA  \\\n",
       "0   Orioles    Braves                D  0.549383     47.3  26.91  0.326   \n",
       "1   Pirates    Tigers                L  0.481481     47.0  26.13  0.318   \n",
       "2  BlueJays  Phillies                L  0.549383     46.7  28.14  0.327   \n",
       "3      Reds   Indians                L  0.419753     46.7  26.46  0.311   \n",
       "4    Braves   Orioles                L  0.422360     45.5  26.35  0.304   \n",
       "\n",
       "       W%.1  B_index.1  LV2.1  wOBA.1  \n",
       "0  0.422360       45.5  26.35   0.304  \n",
       "1  0.534161       48.0  27.31   0.330  \n",
       "2  0.438272       47.0  28.53   0.296  \n",
       "3  0.583851       46.4  30.09   0.326  \n",
       "4  0.549383       47.3  26.91   0.326  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWAY</th>\n",
       "      <th>HOME</th>\n",
       "      <th>HOME_TEAM_RESULT</th>\n",
       "      <th>W%</th>\n",
       "      <th>B_index</th>\n",
       "      <th>LV2</th>\n",
       "      <th>wOBA</th>\n",
       "      <th>WAR</th>\n",
       "      <th>WAR.1</th>\n",
       "      <th>W%.1</th>\n",
       "      <th>B_index.1</th>\n",
       "      <th>LV2.1</th>\n",
       "      <th>wOBA.1</th>\n",
       "      <th>WAR.2</th>\n",
       "      <th>WAR.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orioles</td>\n",
       "      <td>Braves</td>\n",
       "      <td>D</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>47.3</td>\n",
       "      <td>26.91</td>\n",
       "      <td>0.326</td>\n",
       "      <td>15.4</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>45.5</td>\n",
       "      <td>26.35</td>\n",
       "      <td>0.304</td>\n",
       "      <td>8.9</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates</td>\n",
       "      <td>Tigers</td>\n",
       "      <td>L</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>47.0</td>\n",
       "      <td>26.13</td>\n",
       "      <td>0.318</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.534161</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27.31</td>\n",
       "      <td>0.330</td>\n",
       "      <td>17.4</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlueJays</td>\n",
       "      <td>Phillies</td>\n",
       "      <td>L</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>46.7</td>\n",
       "      <td>28.14</td>\n",
       "      <td>0.327</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>47.0</td>\n",
       "      <td>28.53</td>\n",
       "      <td>0.296</td>\n",
       "      <td>13.6</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reds</td>\n",
       "      <td>Indians</td>\n",
       "      <td>L</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>46.7</td>\n",
       "      <td>26.46</td>\n",
       "      <td>0.311</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.583851</td>\n",
       "      <td>46.4</td>\n",
       "      <td>30.09</td>\n",
       "      <td>0.326</td>\n",
       "      <td>18.7</td>\n",
       "      <td>26.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Braves</td>\n",
       "      <td>Orioles</td>\n",
       "      <td>L</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>45.5</td>\n",
       "      <td>26.35</td>\n",
       "      <td>0.304</td>\n",
       "      <td>8.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>47.3</td>\n",
       "      <td>26.91</td>\n",
       "      <td>0.326</td>\n",
       "      <td>15.4</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AWAY      HOME HOME_TEAM_RESULT        W%  B_index    LV2   wOBA   WAR  \\\n",
       "0   Orioles    Braves                D  0.549383     47.3  26.91  0.326  15.4   \n",
       "1   Pirates    Tigers                L  0.481481     47.0  26.13  0.318   9.2   \n",
       "2  BlueJays  Phillies                L  0.549383     46.7  28.14  0.327  19.0   \n",
       "3      Reds   Indians                L  0.419753     46.7  26.46  0.311  -1.4   \n",
       "4    Braves   Orioles                L  0.422360     45.5  26.35  0.304   8.9   \n",
       "\n",
       "   WAR.1      W%.1  B_index.1  LV2.1  wOBA.1  WAR.2  WAR.3  \n",
       "0   20.2  0.422360       45.5  26.35   0.304    8.9   10.0  \n",
       "1   17.3  0.534161       48.0  27.31   0.330   17.4   19.4  \n",
       "2   23.7  0.438272       47.0  28.53   0.296   13.6   10.2  \n",
       "3   15.9  0.583851       46.4  30.09   0.326   18.7   26.7  \n",
       "4   10.0  0.549383       47.3  26.91   0.326   15.4   20.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWAY</th>\n",
       "      <th>HOME</th>\n",
       "      <th>HOME_TEAM_RESULT</th>\n",
       "      <th>W%</th>\n",
       "      <th>Off</th>\n",
       "      <th>K%</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orioles</td>\n",
       "      <td>Braves</td>\n",
       "      <td>D</td>\n",
       "      <td>-0.127022</td>\n",
       "      <td>-128.6</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates</td>\n",
       "      <td>Tigers</td>\n",
       "      <td>L</td>\n",
       "      <td>0.052680</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlueJays</td>\n",
       "      <td>Phillies</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-153.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reds</td>\n",
       "      <td>Indians</td>\n",
       "      <td>L</td>\n",
       "      <td>0.164098</td>\n",
       "      <td>109.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Braves</td>\n",
       "      <td>Orioles</td>\n",
       "      <td>L</td>\n",
       "      <td>0.127022</td>\n",
       "      <td>128.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AWAY      HOME HOME_TEAM_RESULT        W%    Off   K%    AVG\n",
       "0   Orioles    Braves                D -0.127022 -128.6 -1.7 -0.001\n",
       "1   Pirates    Tigers                L  0.052680   42.8  0.0  0.010\n",
       "2  BlueJays  Phillies                L -0.111111 -153.7  1.1 -0.008\n",
       "3      Reds   Indians                L  0.164098  109.3 -0.9  0.006\n",
       "4    Braves   Orioles                L  0.127022  128.6  1.7  0.001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWAY</th>\n",
       "      <th>HOME</th>\n",
       "      <th>HOME_TEAM_RESULT</th>\n",
       "      <th>W%</th>\n",
       "      <th>Off</th>\n",
       "      <th>K%</th>\n",
       "      <th>AVG</th>\n",
       "      <th>P_Index</th>\n",
       "      <th>B_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orioles</td>\n",
       "      <td>Braves</td>\n",
       "      <td>D</td>\n",
       "      <td>-0.127022</td>\n",
       "      <td>-128.6</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates</td>\n",
       "      <td>Tigers</td>\n",
       "      <td>L</td>\n",
       "      <td>0.052680</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlueJays</td>\n",
       "      <td>Phillies</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-153.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reds</td>\n",
       "      <td>Indians</td>\n",
       "      <td>L</td>\n",
       "      <td>0.164098</td>\n",
       "      <td>109.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.55</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Braves</td>\n",
       "      <td>Orioles</td>\n",
       "      <td>L</td>\n",
       "      <td>0.127022</td>\n",
       "      <td>128.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AWAY      HOME HOME_TEAM_RESULT        W%    Off   K%    AVG  P_Index  \\\n",
       "0   Orioles    Braves                D -0.127022 -128.6 -1.7 -0.001    -0.51   \n",
       "1   Pirates    Tigers                L  0.052680   42.8  0.0  0.010     0.82   \n",
       "2  BlueJays  Phillies                L -0.111111 -153.7  1.1 -0.008     0.45   \n",
       "3      Reds   Indians                L  0.164098  109.3 -0.9  0.006     2.55   \n",
       "4    Braves   Orioles                L  0.127022  128.6  1.7  0.001     0.51   \n",
       "\n",
       "   B_index  \n",
       "0     -1.8  \n",
       "1      1.0  \n",
       "2      0.3  \n",
       "3     -0.3  \n",
       "4      1.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWAY</th>\n",
       "      <th>HOME</th>\n",
       "      <th>HOME_TEAM_RESULT</th>\n",
       "      <th>W%</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LOB%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>FIP</th>\n",
       "      <th>xFIP</th>\n",
       "      <th>WAR</th>\n",
       "      <th>...</th>\n",
       "      <th>WAR.3</th>\n",
       "      <th>rPM.1</th>\n",
       "      <th>DRS.1</th>\n",
       "      <th>BIZ.1</th>\n",
       "      <th>RZR.1</th>\n",
       "      <th>FSR.1</th>\n",
       "      <th>RngR.1</th>\n",
       "      <th>ErrR.1</th>\n",
       "      <th>UZR.1</th>\n",
       "      <th>Def.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orioles</td>\n",
       "      <td>Braves</td>\n",
       "      <td>D</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.299</td>\n",
       "      <td>73.8</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.34</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-24</td>\n",
       "      <td>-29</td>\n",
       "      <td>2147</td>\n",
       "      <td>0.792</td>\n",
       "      <td>-46</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>-27.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates</td>\n",
       "      <td>Tigers</td>\n",
       "      <td>L</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.306</td>\n",
       "      <td>72.5</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.28</td>\n",
       "      <td>9.2</td>\n",
       "      <td>...</td>\n",
       "      <td>19.4</td>\n",
       "      <td>-51</td>\n",
       "      <td>-60</td>\n",
       "      <td>2158</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-1</td>\n",
       "      <td>-25.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>-20.8</td>\n",
       "      <td>-12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlueJays</td>\n",
       "      <td>Phillies</td>\n",
       "      <td>L</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.282</td>\n",
       "      <td>74.5</td>\n",
       "      <td>3.79</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.02</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2</td>\n",
       "      <td>-20</td>\n",
       "      <td>-30</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.830</td>\n",
       "      <td>-20</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reds</td>\n",
       "      <td>Indians</td>\n",
       "      <td>L</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.290</td>\n",
       "      <td>72.8</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.79</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>26.7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>2063</td>\n",
       "      <td>0.829</td>\n",
       "      <td>7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>35.6</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Braves</td>\n",
       "      <td>Orioles</td>\n",
       "      <td>L</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.293</td>\n",
       "      <td>70.2</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.48</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>20.2</td>\n",
       "      <td>-34</td>\n",
       "      <td>-30</td>\n",
       "      <td>2074</td>\n",
       "      <td>0.822</td>\n",
       "      <td>13</td>\n",
       "      <td>-20.7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>-12.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AWAY      HOME HOME_TEAM_RESULT        W%  BABIP  LOB%   ERA   FIP  \\\n",
       "0   Orioles    Braves                D  0.549383  0.299  73.8  4.22  4.31   \n",
       "1   Pirates    Tigers                L  0.481481  0.306  72.5  4.22  4.30   \n",
       "2  BlueJays  Phillies                L  0.549383  0.282  74.5  3.79  4.04   \n",
       "3      Reds   Indians                L  0.419753  0.290  72.8  4.91  5.24   \n",
       "4    Braves   Orioles                L  0.422360  0.293  70.2  4.51  4.32   \n",
       "\n",
       "   xFIP   WAR  ...    WAR.3  rPM.1  DRS.1  BIZ.1  RZR.1  FSR.1  RngR.1  \\\n",
       "0  4.34  15.4  ...     10.0    -24    -29   2147  0.792    -46   -11.5   \n",
       "1  4.28   9.2  ...     19.4    -51    -60   2158  0.811     -1   -25.8   \n",
       "2  4.02  19.0  ...     10.2    -20    -30   2012  0.830    -20    18.0   \n",
       "3  4.79  -1.4  ...     26.7      7     15   2063  0.829      7    35.1   \n",
       "4  4.48   8.9  ...     20.2    -34    -30   2074  0.822     13   -20.7   \n",
       "\n",
       "   ErrR.1  UZR.1  Def.3  \n",
       "0    -7.5  -12.9  -27.9  \n",
       "1    17.5  -20.8  -12.8  \n",
       "2     4.4   18.1   19.1  \n",
       "3    -2.9   35.6   41.6  \n",
       "4    13.3  -12.6  -12.6  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read data and drop redundant column.\n",
    "data1 = pd.read_csv('Set1_training.csv')\n",
    "data_test1 = pd.read_csv('Set1_testing.csv')\n",
    "data2 = pd.read_csv('Set2_training.csv')\n",
    "data_test2 = pd.read_csv('Set2_testing.csv')\n",
    "data3 = pd.read_csv('Set3_training.csv')\n",
    "data_test3 = pd.read_csv('Set3_testing.csv')\n",
    "data4 = pd.read_csv('Set4_training.csv')\n",
    "data_test4 = pd.read_csv('Set4_testing.csv')\n",
    "data5 = pd.read_csv('Set5_training.csv')\n",
    "data_test5 = pd.read_csv('Set5_testing.csv')\n",
    "data6 = pd.read_csv('Set6_training.csv')\n",
    "data_test6 = pd.read_csv('Set6_testing.csv')\n",
    "dataC = pd.read_csv('SetC_training.csv')\n",
    "data_testC = pd.read_csv('SetC_testing.csv')\n",
    "# Preview data.\n",
    "display(data1.head())\n",
    "display(data2.head())\n",
    "display(data3.head())\n",
    "display(data4.head())\n",
    "display(data5.head())\n",
    "display(data6.head())\n",
    "display(dataC.head())\n",
    "\n",
    "#\"ACCRONYMS:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\"\n",
    "\n",
    "#Input - 12 other features (fouls, shots, goals, misses,corners, red card, yellow cards)\n",
    "#Output - Full Time Result (H=Home Win, D=Draw, A=Away Win) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matches: 2734\n",
      "Number of features: 58\n",
      "Number of matches won by home team: 1439\n",
      "Win rate of home team: 52.63%\n"
     ]
    }
   ],
   "source": [
    "#what is the win rate for the home team?\n",
    "\n",
    "# Total number of matches.\n",
    "n_matches = dataC.shape[0]\n",
    "\n",
    "# Calculate number of features. -1 because we are saving one as the target variable (win/lose/draw)\n",
    "n_features = dataC.shape[1] - 1\n",
    "\n",
    "# Calculate matches won by home team.\n",
    "n_homewins = len(dataC[dataC.HOME_TEAM_RESULT == 'W'])\n",
    "\n",
    "# Calculate win rate for home team.\n",
    "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of matches: {}\".format(n_matches))\n",
    "print (\"Number of features: {}\".format(n_features))\n",
    "print (\"Number of matches won by home team: {}\".format(n_homewins))\n",
    "print (\"Win rate of home team: {:.2f}%\".format(win_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualising distribution of data\n",
    "#from pandas.plotting import scatter_matrix\n",
    "\n",
    "#the scatter matrix is plotting each of the columns specified against each other column.\n",
    "#You would have observed that the diagonal graph is defined as a histogram, which means that in the \n",
    "#section of the plot matrix where the variable is against itself, a histogram is plotted.\n",
    "\n",
    "#Scatter plots show how much one variable is affected by another. \n",
    "#The relationship between two variables is called their correlation\n",
    "#negative vs positive correlation\n",
    "\n",
    "#HTGD - Home team goal difference\n",
    "#ATGD - away team goal difference\n",
    "#HTP - Home team points\n",
    "#ATP - Away team points\n",
    "#DiffFormPts Diff in points\n",
    "#DiffLP - Differnece in last years prediction\n",
    "\n",
    "#scatter_matrix(data[['HOME_SCORE','AWAY_SCORE']], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate into feature set and target variable\n",
    "#Home team result:W=Home Win, D=Draw, L=Away Win\n",
    "X_all1 = data1.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_all1 = data1['HOME_TEAM_RESULT']\n",
    "X_all2 = data2.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_all2 = data2['HOME_TEAM_RESULT']\n",
    "X_all3 = data3.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_all3 = data3['HOME_TEAM_RESULT']\n",
    "X_all4 = data4.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_all4 = data4['HOME_TEAM_RESULT']\n",
    "X_all5 = data5.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_all5 = data5['HOME_TEAM_RESULT']\n",
    "X_all6 = data6.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_all6 = data6['HOME_TEAM_RESULT']\n",
    "X_allC = dataC.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_allC = dataC['HOME_TEAM_RESULT']\n",
    "\n",
    "X_test1 = data_test1.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_test1 = data_test1['HOME_TEAM_RESULT']\n",
    "X_test2 = data_test2.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_test2 = data_test2['HOME_TEAM_RESULT']\n",
    "X_test3 = data_test3.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_test3 = data_test3['HOME_TEAM_RESULT']\n",
    "X_test4 = data_test4.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_test4 = data_test4['HOME_TEAM_RESULT']\n",
    "X_test5 = data_test5.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_test5 = data_test5['HOME_TEAM_RESULT']\n",
    "X_test6 = data_test6.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_test6 = data_test6['HOME_TEAM_RESULT']\n",
    "X_testC = data_testC.drop(['HOME_TEAM_RESULT','AWAY','HOME'],1)\n",
    "y_testC = data_testC['HOME_TEAM_RESULT']\n",
    "\n",
    "\n",
    "# Standardising the data.\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Center to the mean and component wise scale to unit variance.\n",
    "cols1 = [['W%', 'BABIP', 'ERA', 'K%', 'K%.1', 'AVG', 'SLG', 'W%.1', 'BABIP.1', 'ERA.1', 'K%.2', 'K%.3', 'AVG.1', 'SLG.1']]\n",
    "cols2 = [['W%', 'BABIP', 'ERA', 'K%', 'K%.1', 'AVG', 'SLG', 'P_Index', 'B_index', 'W%.1', 'BABIP.1', 'ERA.1', 'K%.2', 'K%.3', 'AVG.1', 'SLG.1', 'P_Index.1', 'B_index.1']]\n",
    "cols3 = [['W%', 'B_index', 'LV2', 'wOBA', 'W%.1', 'B_index.1', 'LV2.1', 'wOBA.1']]\n",
    "cols4 = [['W%' , 'B_index' , 'LV2' , 'wOBA' , 'WAR' , 'WAR.1']]\n",
    "cols5 = [['W%' , 'Off' , 'K%' , 'AVG']]\n",
    "cols6 = [['W%' , 'Off' , 'K%' , 'AVG' , 'P_Index' , 'B_index']]\n",
    "colsC = [['W%', 'BABIP', 'LOB%', 'ERA', 'FIP', 'xFIP', 'WAR', 'K/BB', 'K%', 'HR', 'K%.1', 'AVG', 'OBP', 'SLG', 'wOBA', 'wRC+', 'Off', 'Def', 'WAR.1', 'rPM', 'DRS', 'BIZ', 'RZR', 'FSR', 'RngR', 'ErrR', 'UZR', 'Def.1', 'W%.1', 'BABIP.1', 'LOB%.1', 'ERA.1', 'FIP.1', 'xFIP.1', 'WAR.2', 'K/BB.1', 'K%.2', 'HR.1', 'K%.3', 'AVG.1', 'OBP.1', 'SLG.1', 'wOBA.1', 'wRC+.1', 'Off.1', 'Def.2', 'WAR.3', 'rPM.1', 'DRS.1', 'BIZ.1', 'RZR.1', 'FSR.1', 'RngR.1', 'ErrR.1', 'UZR.1', 'Def.3']]\n",
    "\n",
    "for col in cols1:\n",
    "    X_all1[col] = scale(X_all1[col])\n",
    "    X_test1[col] = scale(X_test1[col])\n",
    "    \n",
    "for col in cols2:\n",
    "    X_all2[col] = scale(X_all2[col])\n",
    "    X_test2[col] = scale(X_test2[col])\n",
    "    \n",
    "for col in cols3:\n",
    "    X_all3[col] = scale(X_all3[col])\n",
    "    X_test3[col] = scale(X_test3[col])\n",
    "    \n",
    "for col in cols4:\n",
    "    X_all4[col] = scale(X_all4[col])\n",
    "    X_test4[col] = scale(X_test4[col])\n",
    "    \n",
    "for col in cols5:\n",
    "    X_all5[col] = scale(X_all5[col])\n",
    "    X_test5[col] = scale(X_test5[col])\n",
    "        \n",
    "for col in cols6:\n",
    "    X_all6[col] = scale(X_all6[col])\n",
    "    X_test6[col] = scale(X_test6[col])\n",
    "    \n",
    "for col in colsC:\n",
    "    X_allC[col] = scale(X_allC[col])\n",
    "    X_testC[col] = scale(X_testC[col])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (56 total features):\n",
      "['W%', 'BABIP', 'LOB%', 'ERA', 'FIP', 'xFIP', 'WAR', 'K/BB', 'K%', 'HR', 'K%.1', 'AVG', 'OBP', 'SLG', 'wOBA', 'wRC+', 'Off', 'Def', 'WAR.1', 'rPM', 'DRS', 'BIZ', 'RZR', 'FSR', 'RngR', 'ErrR', 'UZR', 'Def.1', 'W%.1', 'BABIP.1', 'LOB%.1', 'ERA.1', 'FIP.1', 'xFIP.1', 'WAR.2', 'K/BB.1', 'K%.2', 'HR.1', 'K%.3', 'AVG.1', 'OBP.1', 'SLG.1', 'wOBA.1', 'wRC+.1', 'Off.1', 'Def.2', 'WAR.3', 'rPM.1', 'DRS.1', 'BIZ.1', 'RZR.1', 'FSR.1', 'RngR.1', 'ErrR.1', 'UZR.1', 'Def.3']\n"
     ]
    }
   ],
   "source": [
    "#we want continous vars that are integers for our input data, so lets remove any categorical vars\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the football data and converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "#my_model = PCA(n_components=0.99, svd_solver='full')\n",
    "#U=my_model.fit_transform(X_all)\n",
    "\n",
    "X_all1 = preprocess_features(X_all1)\n",
    "X_all2 = preprocess_features(X_all2)\n",
    "X_all3 = preprocess_features(X_all3)\n",
    "X_all4 = preprocess_features(X_all4)\n",
    "X_all5 = preprocess_features(X_all5)\n",
    "X_all6 = preprocess_features(X_all6)\n",
    "X_allC = preprocess_features(X_allC)\n",
    "\n",
    "X_test1 = preprocess_features(X_test1)\n",
    "X_test2 = preprocess_features(X_test2)\n",
    "X_test3 = preprocess_features(X_test3)\n",
    "X_test4 = preprocess_features(X_test4)\n",
    "X_test5 = preprocess_features(X_test5)\n",
    "X_test6 = preprocess_features(X_test6)\n",
    "X_testC = preprocess_features(X_testC)\n",
    "print (\"Processed feature columns ({} total features):\\n{}\".format(len(X_allC.columns), list(X_allC.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W%</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>LOB%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>FIP</th>\n",
       "      <th>xFIP</th>\n",
       "      <th>WAR</th>\n",
       "      <th>K/BB</th>\n",
       "      <th>K%</th>\n",
       "      <th>HR</th>\n",
       "      <th>...</th>\n",
       "      <th>WAR.3</th>\n",
       "      <th>rPM.1</th>\n",
       "      <th>DRS.1</th>\n",
       "      <th>BIZ.1</th>\n",
       "      <th>RZR.1</th>\n",
       "      <th>FSR.1</th>\n",
       "      <th>RngR.1</th>\n",
       "      <th>ErrR.1</th>\n",
       "      <th>UZR.1</th>\n",
       "      <th>Def.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710381</td>\n",
       "      <td>0.236304</td>\n",
       "      <td>0.320201</td>\n",
       "      <td>0.150904</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.554531</td>\n",
       "      <td>0.159073</td>\n",
       "      <td>-0.941959</td>\n",
       "      <td>-0.429612</td>\n",
       "      <td>2.070131</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.284302</td>\n",
       "      <td>-0.741165</td>\n",
       "      <td>-0.750842</td>\n",
       "      <td>0.779036</td>\n",
       "      <td>-0.976932</td>\n",
       "      <td>-1.712538</td>\n",
       "      <td>-0.504320</td>\n",
       "      <td>-0.864981</td>\n",
       "      <td>-0.495872</td>\n",
       "      <td>-0.911051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.336003</td>\n",
       "      <td>0.842766</td>\n",
       "      <td>-0.306001</td>\n",
       "      <td>0.150904</td>\n",
       "      <td>0.334466</td>\n",
       "      <td>0.339914</td>\n",
       "      <td>-0.950565</td>\n",
       "      <td>-0.887012</td>\n",
       "      <td>-0.871426</td>\n",
       "      <td>-1.076126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030591</td>\n",
       "      <td>-1.570765</td>\n",
       "      <td>-1.542719</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>0.106564</td>\n",
       "      <td>-0.073575</td>\n",
       "      <td>-1.055679</td>\n",
       "      <td>1.996630</td>\n",
       "      <td>-0.759396</td>\n",
       "      <td>-0.444021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.710381</td>\n",
       "      <td>-1.236532</td>\n",
       "      <td>0.657387</td>\n",
       "      <td>-0.869430</td>\n",
       "      <td>-0.394431</td>\n",
       "      <td>-0.590091</td>\n",
       "      <td>0.803380</td>\n",
       "      <td>0.596543</td>\n",
       "      <td>0.177881</td>\n",
       "      <td>1.063329</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.256326</td>\n",
       "      <td>-0.618261</td>\n",
       "      <td>-0.776386</td>\n",
       "      <td>-0.721877</td>\n",
       "      <td>1.190060</td>\n",
       "      <td>-0.765582</td>\n",
       "      <td>0.633099</td>\n",
       "      <td>0.497146</td>\n",
       "      <td>0.538209</td>\n",
       "      <td>0.542617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.287262</td>\n",
       "      <td>-0.543433</td>\n",
       "      <td>-0.161492</td>\n",
       "      <td>1.788183</td>\n",
       "      <td>2.969707</td>\n",
       "      <td>2.164155</td>\n",
       "      <td>-2.847689</td>\n",
       "      <td>-1.876049</td>\n",
       "      <td>-0.871426</td>\n",
       "      <td>-0.730037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051731</td>\n",
       "      <td>0.211339</td>\n",
       "      <td>0.373113</td>\n",
       "      <td>-0.154865</td>\n",
       "      <td>1.133034</td>\n",
       "      <td>0.217796</td>\n",
       "      <td>1.292417</td>\n",
       "      <td>-0.338445</td>\n",
       "      <td>1.121965</td>\n",
       "      <td>1.238521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.247084</td>\n",
       "      <td>-0.283520</td>\n",
       "      <td>-1.413896</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.390535</td>\n",
       "      <td>1.055303</td>\n",
       "      <td>-1.004257</td>\n",
       "      <td>-1.079325</td>\n",
       "      <td>-0.871426</td>\n",
       "      <td>-2.051465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142497</td>\n",
       "      <td>-1.048424</td>\n",
       "      <td>-0.776386</td>\n",
       "      <td>-0.032569</td>\n",
       "      <td>0.733851</td>\n",
       "      <td>0.436324</td>\n",
       "      <td>-0.859040</td>\n",
       "      <td>1.515879</td>\n",
       "      <td>-0.485865</td>\n",
       "      <td>-0.437836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         W%     BABIP      LOB%       ERA       FIP      xFIP       WAR  \\\n",
       "0  0.710381  0.236304  0.320201  0.150904  0.362500  0.554531  0.159073   \n",
       "1 -0.336003  0.842766 -0.306001  0.150904  0.334466  0.339914 -0.950565   \n",
       "2  0.710381 -1.236532  0.657387 -0.869430 -0.394431 -0.590091  0.803380   \n",
       "3 -1.287262 -0.543433 -0.161492  1.788183  2.969707  2.164155 -2.847689   \n",
       "4 -1.247084 -0.283520 -1.413896  0.839036  0.390535  1.055303 -1.004257   \n",
       "\n",
       "       K/BB        K%        HR    ...        WAR.3     rPM.1     DRS.1  \\\n",
       "0 -0.941959 -0.429612  2.070131    ...    -1.284302 -0.741165 -0.750842   \n",
       "1 -0.887012 -0.871426 -1.076126    ...     0.030591 -1.570765 -1.542719   \n",
       "2  0.596543  0.177881  1.063329    ...    -1.256326 -0.618261 -0.776386   \n",
       "3 -1.876049 -0.871426 -0.730037    ...     1.051731  0.211339  0.373113   \n",
       "4 -1.079325 -0.871426 -2.051465    ...     0.142497 -1.048424 -0.776386   \n",
       "\n",
       "      BIZ.1     RZR.1     FSR.1    RngR.1    ErrR.1     UZR.1     Def.3  \n",
       "0  0.779036 -0.976932 -1.712538 -0.504320 -0.864981 -0.495872 -0.911051  \n",
       "1  0.901333  0.106564 -0.073575 -1.055679  1.996630 -0.759396 -0.444021  \n",
       "2 -0.721877  1.190060 -0.765582  0.633099  0.497146  0.538209  0.542617  \n",
       "3 -0.154865  1.133034  0.217796  1.292417 -0.338445  1.121965  1.238521  \n",
       "4 -0.032569  0.733851  0.436324 -0.859040  1.515879 -0.485865 -0.437836  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the feature information by printing the first five rows\n",
    "print (\"\\nFeature values:\")\n",
    "display(X_allC.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Shuffle and split the dataset into training and testing set.\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "#                                                    test_size = 0.1,\n",
    "#                                                    random_state = 2,\n",
    "#                                                    stratify = y_all)\n",
    "\n",
    "#X_train=X_all\n",
    "#X_test=X_test\n",
    "#y_train=y_all\n",
    "#y_test=y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for measuring training time\n",
    "from time import time \n",
    "# F1 score (also F-score or F-measure) is a measure of a test's accuracy. \n",
    "#It considers both the precision p and the recall r of the test to compute \n",
    "#the score: p is the number of correct positive results divided by the number of \n",
    "#all positive results, and r is the number of correct positive results divided by \n",
    "#the number of positive results that should have been returned. The F1 score can be \n",
    "#interpreted as a weighted average of the precision and recall, where an F1 score \n",
    "#reaches its best value at 1 and worst at 0.\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):#target is y-train or y_test\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    end = time()\n",
    "    # Print and return results\n",
    "    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target, y_pred, pos_label='W',average='micro'), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print (f1, acc)\n",
    "    print (\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print (\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/logisticregression-predictingthechancesofcoronaryheartdisease-091203130638-phpapp01/95/logistic-regression-predicting-the-chances-of-coronary-heart-disease-2-728.jpg?cb=1259845609\"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://i.ytimg.com/vi/HdB-z0TJRK4/maxresdefault.jpg \"Logo Title Text 1\")\n",
    "\n",
    "Support Vector Machine\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/supportvectormachine-121112135318-phpapp01/95/support-vector-machine-3-638.jpg?cb=1352729591 \"Logo Title Text 1\")\n",
    "![alt text](http://docs.opencv.org/2.4/_images/optimal-hyperplane.png \"Logo Title Text 1\")\n",
    "\n",
    "XGBoost\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/cart.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/twocart.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/0782ee51-165d-4e34-a09c-2b7f8dacff01-150403064822-conversion-gate01/95/feature-importance-analysis-with-xgboost-in-tax-audit-17-638.jpg?cb=1450092771 \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/0782ee51-165d-4e34-a09c-2b7f8dacff01-150403064822-conversion-gate01/95/feature-importance-analysis-with-xgboost-in-tax-audit-18-638.jpg?cb=1450092771 \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.562545720556 0.562545720556\n",
      "F1 score and accuracy score for training set: 0.5625 , 0.5625.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5241 , 0.5241.\n",
      "Training a LogisticRegression using a training set size of 2734. . .\n",
      "Trained model in 0.0313 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.562545720556 0.562545720556\n",
      "F1 score and accuracy score for training set: 0.5625 , 0.5625.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5241 , 0.5241.\n",
      "Training a LogisticRegression using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.561814191661 0.561814191661\n",
      "F1 score and accuracy score for training set: 0.5618 , 0.5618.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5194 , 0.5194.\n",
      "Training a LogisticRegression using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.0982 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.56035113387 0.56035113387\n",
      "F1 score and accuracy score for training set: 0.5604 , 0.5604.\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score and accuracy score for test set: 0.5216 , 0.5216.\n",
      "Training a LogisticRegression using a training set size of 2734. . .\n",
      "Trained model in 0.0060 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.565471836138 0.565471836138\n",
      "F1 score and accuracy score for training set: 0.5655 , 0.5655.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5198 , 0.5198.\n",
      "Training a LogisticRegression using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.565471836138 0.565471836138\n",
      "F1 score and accuracy score for training set: 0.5655 , 0.5655.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5198 , 0.5198.\n",
      "Training a LogisticRegression using a training set size of 2734. . .\n",
      "Trained model in 1.0870 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.578639356255 0.578639356255\n",
      "F1 score and accuracy score for training set: 0.5786 , 0.5786.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5147 , 0.5147.\n",
      "\n",
      "Training a SVC using a training set size of 2734. . .\n",
      "Trained model in 1.4430 seconds\n",
      "Made predictions in 0.1406 seconds.\n",
      "0.686905632772 0.686905632772\n",
      "F1 score and accuracy score for training set: 0.6869 , 0.6869.\n",
      "Made predictions in 0.1836 seconds.\n",
      "F1 score and accuracy score for test set: 0.5018 , 0.5018.\n",
      "Training a SVC using a training set size of 2734. . .\n",
      "Trained model in 1.1544 seconds\n",
      "Made predictions in 0.1576 seconds.\n",
      "0.686905632772 0.686905632772\n",
      "F1 score and accuracy score for training set: 0.6869 , 0.6869.\n",
      "Made predictions in 0.1606 seconds.\n",
      "F1 score and accuracy score for test set: 0.5007 , 0.5007.\n",
      "Training a SVC using a training set size of 2734. . .\n",
      "Trained model in 6.1003 seconds\n",
      "Made predictions in 0.1292 seconds.\n",
      "0.681419166057 0.681419166057\n",
      "F1 score and accuracy score for training set: 0.6814 , 0.6814.\n",
      "Made predictions in 0.1254 seconds.\n",
      "F1 score and accuracy score for test set: 0.5000 , 0.5000.\n",
      "Training a SVC using a training set size of 2734. . .\n",
      "Trained model in 0.4705 seconds\n",
      "Made predictions in 0.1412 seconds.\n",
      "0.686905632772 0.686905632772\n",
      "F1 score and accuracy score for training set: 0.6869 , 0.6869.\n",
      "Made predictions in 0.1412 seconds.\n",
      "F1 score and accuracy score for test set: 0.5018 , 0.5018.\n",
      "Training a SVC using a training set size of 2734. . .\n",
      "Trained model in 10.2695 seconds\n",
      "Made predictions in 0.1094 seconds.\n",
      "0.638990490124 0.638990490124\n",
      "F1 score and accuracy score for training set: 0.6390 , 0.6390.\n",
      "Made predictions in 0.1086 seconds.\n",
      "F1 score and accuracy score for test set: 0.5065 , 0.5065.\n",
      "Training a SVC using a training set size of 2734. . .\n",
      "Trained model in 14.1854 seconds\n",
      "Made predictions in 0.1250 seconds.\n",
      "0.664228237015 0.664228237015\n",
      "F1 score and accuracy score for training set: 0.6642 , 0.6642.\n",
      "Made predictions in 0.1283 seconds.\n",
      "F1 score and accuracy score for test set: 0.5183 , 0.5183.\n",
      "Training a SVC using a training set size of 2734. . .\n",
      "Trained model in 0.5742 seconds\n",
      "Made predictions in 0.3250 seconds.\n",
      "0.686905632772 0.686905632772\n",
      "F1 score and accuracy score for training set: 0.6869 , 0.6869.\n",
      "Made predictions in 0.3181 seconds.\n",
      "F1 score and accuracy score for test set: 0.5097 , 0.5097.\n",
      "\n",
      "Training a XGBClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.4107 seconds\n",
      "Made predictions in 0.0158 seconds.\n",
      "0.627651792246 0.627651792246\n",
      "F1 score and accuracy score for training set: 0.6277 , 0.6277.\n",
      "Made predictions in 0.0313 seconds.\n",
      "F1 score and accuracy score for test set: 0.5226 , 0.5226.\n",
      "Training a XGBClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.5686 seconds\n",
      "Made predictions in 0.0156 seconds.\n",
      "0.626554498903 0.626554498903\n",
      "F1 score and accuracy score for training set: 0.6266 , 0.6266.\n",
      "Made predictions in 0.0313 seconds.\n",
      "F1 score and accuracy score for test set: 0.5151 , 0.5151.\n",
      "Training a XGBClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.2889 seconds\n",
      "Made predictions in 0.0240 seconds.\n",
      "0.623628383321 0.623628383321\n",
      "F1 score and accuracy score for training set: 0.6236 , 0.6236.\n",
      "Made predictions in 0.0230 seconds.\n",
      "F1 score and accuracy score for test set: 0.5248 , 0.5248.\n",
      "Training a XGBClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.3612 seconds\n",
      "Made predictions in 0.0156 seconds.\n",
      "0.627286027798 0.627286027798\n",
      "F1 score and accuracy score for training set: 0.6273 , 0.6273.\n",
      "Made predictions in 0.0313 seconds.\n",
      "F1 score and accuracy score for test set: 0.5277 , 0.5277.\n",
      "Training a XGBClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.2138 seconds\n",
      "Made predictions in 0.0220 seconds.\n",
      "0.616678858815 0.616678858815\n",
      "F1 score and accuracy score for training set: 0.6167 , 0.6167.\n",
      "Made predictions in 0.0102 seconds.\n",
      "F1 score and accuracy score for test set: 0.5158 , 0.5158.\n",
      "Training a XGBClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.2950 seconds\n",
      "Made predictions in 0.0313 seconds.\n",
      "0.621799561083 0.621799561083\n",
      "F1 score and accuracy score for training set: 0.6218 , 0.6218.\n",
      "Made predictions in 0.0156 seconds.\n",
      "F1 score and accuracy score for test set: 0.5169 , 0.5169.\n",
      "Training a XGBClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 1.6271 seconds\n",
      "Made predictions in 0.0470 seconds.\n",
      "0.63643013899 0.63643013899\n",
      "F1 score and accuracy score for training set: 0.6364 , 0.6364.\n",
      "Made predictions in 0.0281 seconds.\n",
      "F1 score and accuracy score for test set: 0.5295 , 0.5295.\n",
      "\n",
      "Training a KNeighborsClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0040 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made predictions in 0.5100 seconds.\n",
      "0.554498902707 0.554498902707\n",
      "F1 score and accuracy score for training set: 0.5545 , 0.5545.\n",
      "Made predictions in 0.5056 seconds.\n",
      "F1 score and accuracy score for test set: 0.5233 , 0.5233.\n",
      "Training a KNeighborsClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.5505 seconds.\n",
      "0.55559619605 0.55559619605\n",
      "F1 score and accuracy score for training set: 0.5556 , 0.5556.\n",
      "Made predictions in 0.5810 seconds.\n",
      "F1 score and accuracy score for test set: 0.5230 , 0.5230.\n",
      "Training a KNeighborsClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.3956 seconds.\n",
      "0.553401609364 0.553401609364\n",
      "F1 score and accuracy score for training set: 0.5534 , 0.5534.\n",
      "Made predictions in 0.4135 seconds.\n",
      "F1 score and accuracy score for test set: 0.5280 , 0.5280.\n",
      "Training a KNeighborsClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.2952 seconds.\n",
      "0.544623262619 0.544623262619\n",
      "F1 score and accuracy score for training set: 0.5446 , 0.5446.\n",
      "Made predictions in 0.2968 seconds.\n",
      "F1 score and accuracy score for test set: 0.5075 , 0.5075.\n",
      "Training a KNeighborsClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.2729 seconds.\n",
      "0.556327724945 0.556327724945\n",
      "F1 score and accuracy score for training set: 0.5563 , 0.5563.\n",
      "Made predictions in 0.2906 seconds.\n",
      "F1 score and accuracy score for test set: 0.5176 , 0.5176.\n",
      "Training a KNeighborsClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.3138 seconds.\n",
      "0.561448427213 0.561448427213\n",
      "F1 score and accuracy score for training set: 0.5614 , 0.5614.\n",
      "Made predictions in 0.3073 seconds.\n",
      "F1 score and accuracy score for test set: 0.5216 , 0.5216.\n",
      "Training a KNeighborsClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 1.0322 seconds.\n",
      "0.554864667154 0.554864667154\n",
      "F1 score and accuracy score for training set: 0.5549 , 0.5549.\n",
      "Made predictions in 1.0622 seconds.\n",
      "F1 score and accuracy score for test set: 0.5226 , 0.5226.\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 0.0156 seconds.\n",
      "0.567666422824 0.567666422824\n",
      "F1 score and accuracy score for training set: 0.5677 , 0.5677.\n",
      "Made predictions in 0.0157 seconds.\n",
      "F1 score and accuracy score for test set: 0.5216 , 0.5216.\n",
      "Training a RandomForestClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.578639356255 0.578639356255\n",
      "F1 score and accuracy score for training set: 0.5786 , 0.5786.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5183 , 0.5183.\n",
      "Training a RandomForestClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.572421360644 0.572421360644\n",
      "F1 score and accuracy score for training set: 0.5724 , 0.5724.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5158 , 0.5158.\n",
      "Training a RandomForestClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.572421360644 0.572421360644\n",
      "F1 score and accuracy score for training set: 0.5724 , 0.5724.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made predictions in 0.0156 seconds.\n",
      "F1 score and accuracy score for test set: 0.5230 , 0.5230.\n",
      "Training a RandomForestClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0202 seconds\n",
      "Made predictions in 0.0030 seconds.\n",
      "0.577542062911 0.577542062911\n",
      "F1 score and accuracy score for training set: 0.5775 , 0.5775.\n",
      "Made predictions in 0.0029 seconds.\n",
      "F1 score and accuracy score for test set: 0.5165 , 0.5165.\n",
      "Training a RandomForestClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0210 seconds\n",
      "Made predictions in 0.0030 seconds.\n",
      "0.577907827359 0.577907827359\n",
      "F1 score and accuracy score for training set: 0.5779 , 0.5779.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5090 , 0.5090.\n",
      "Training a RandomForestClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0313 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.580102414045 0.580102414045\n",
      "F1 score and accuracy score for training set: 0.5801 , 0.5801.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5172 , 0.5172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training a AdaBoostClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0954 seconds\n",
      "Made predictions in 0.0080 seconds.\n",
      "0.559253840527 0.559253840527\n",
      "F1 score and accuracy score for training set: 0.5593 , 0.5593.\n",
      "Made predictions in 0.0070 seconds.\n",
      "F1 score and accuracy score for test set: 0.5176 , 0.5176.\n",
      "Training a AdaBoostClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0782 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.557059253841 0.557059253841\n",
      "F1 score and accuracy score for training set: 0.5571 , 0.5571.\n",
      "Made predictions in 0.0156 seconds.\n",
      "F1 score and accuracy score for test set: 0.5259 , 0.5259.\n",
      "Training a AdaBoostClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.0928 seconds\n",
      "Made predictions in 0.0080 seconds.\n",
      "0.562545720556 0.562545720556\n",
      "F1 score and accuracy score for training set: 0.5625 , 0.5625.\n",
      "Made predictions in 0.0070 seconds.\n",
      "F1 score and accuracy score for test set: 0.5147 , 0.5147.\n",
      "Training a AdaBoostClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0708 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.562179956108 0.562179956108\n",
      "F1 score and accuracy score for training set: 0.5622 , 0.5622.\n",
      "Made predictions in 0.0156 seconds.\n",
      "F1 score and accuracy score for test set: 0.5295 , 0.5295.\n",
      "Training a AdaBoostClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.0842 seconds\n",
      "Made predictions in 0.0080 seconds.\n",
      "0.561814191661 0.561814191661\n",
      "F1 score and accuracy score for training set: 0.5618 , 0.5618.\n",
      "Made predictions in 0.0092 seconds.\n",
      "F1 score and accuracy score for test set: 0.5068 , 0.5068.\n",
      "Training a AdaBoostClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0676 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.564374542794 0.564374542794\n",
      "F1 score and accuracy score for training set: 0.5644 , 0.5644.\n",
      "Made predictions in 0.0156 seconds.\n",
      "F1 score and accuracy score for test set: 0.5075 , 0.5075.\n",
      "Training a AdaBoostClassifier using a training set size of 2734. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model in 0.1385 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.559253840527 0.559253840527\n",
      "F1 score and accuracy score for training set: 0.5593 , 0.5593.\n",
      "Made predictions in 0.0156 seconds.\n",
      "F1 score and accuracy score for test set: 0.5172 , 0.5172.\n",
      "\n",
      "Training a GaussianNB using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.555230431602 0.555230431602\n",
      "F1 score and accuracy score for training set: 0.5552 , 0.5552.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5050 , 0.5050.\n",
      "Training a GaussianNB using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.543525969276 0.543525969276\n",
      "F1 score and accuracy score for training set: 0.5435 , 0.5435.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.4943 , 0.4943.\n",
      "Training a GaussianNB using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.561448427213 0.561448427213\n",
      "F1 score and accuracy score for training set: 0.5614 , 0.5614.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5176 , 0.5176.\n",
      "Training a GaussianNB using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.557425018288 0.557425018288\n",
      "F1 score and accuracy score for training set: 0.5574 , 0.5574.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5093 , 0.5093.\n",
      "Training a GaussianNB using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.558156547184 0.558156547184\n",
      "F1 score and accuracy score for training set: 0.5582 , 0.5582.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5158 , 0.5158.\n",
      "Training a GaussianNB using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1045: UserWarning: Note that pos_label (set to 'W') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562179956108 0.562179956108\n",
      "F1 score and accuracy score for training set: 0.5622 , 0.5622.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5072 , 0.5072.\n",
      "Training a GaussianNB using a training set size of 2734. . .\n",
      "Trained model in 0.0060 seconds\n",
      "Made predictions in 0.0070 seconds.\n",
      "0.490855888808 0.490855888808\n",
      "F1 score and accuracy score for training set: 0.4909 , 0.4909.\n",
      "Made predictions in 0.0080 seconds.\n",
      "F1 score and accuracy score for test set: 0.4425 , 0.4425.\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0100 seconds\n",
      "Made predictions in 0.0010 seconds.\n",
      "0.686905632772 0.686905632772\n",
      "F1 score and accuracy score for training set: 0.6869 , 0.6869.\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score and accuracy score for test set: 0.4925 , 0.4925.\n",
      "Training a DecisionTreeClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0156 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.686174103877 0.686174103877\n",
      "F1 score and accuracy score for training set: 0.6862 , 0.6862.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.4953 , 0.4953.\n",
      "Training a DecisionTreeClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.686539868325 0.686539868325\n",
      "F1 score and accuracy score for training set: 0.6865 , 0.6865.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.4878 , 0.4878.\n",
      "Training a DecisionTreeClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0156 seconds.\n",
      "0.686905632772 0.686905632772\n",
      "F1 score and accuracy score for training set: 0.6869 , 0.6869.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.4885 , 0.4885.\n",
      "Training a DecisionTreeClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0210 seconds\n",
      "Made predictions in 0.0010 seconds.\n",
      "0.686905632772 0.686905632772\n",
      "F1 score and accuracy score for training set: 0.6869 , 0.6869.\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score and accuracy score for test set: 0.4881 , 0.4881.\n",
      "Training a DecisionTreeClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0100 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.686539868325 0.686539868325\n",
      "F1 score and accuracy score for training set: 0.6865 , 0.6865.\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score and accuracy score for test set: 0.4881 , 0.4881.\n",
      "Training a DecisionTreeClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.0322 seconds\n",
      "Made predictions in 0.0010 seconds.\n",
      "0.686539868325 0.686539868325\n",
      "F1 score and accuracy score for training set: 0.6865 , 0.6865.\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score and accuracy score for test set: 0.4871 , 0.4871.\n",
      "\n",
      "Training a MLPClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.3201 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.539502560351 0.539502560351\n",
      "F1 score and accuracy score for training set: 0.5395 , 0.5395.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5399 , 0.5399.\n",
      "Training a MLPClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.3410 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.567666422824 0.567666422824\n",
      "F1 score and accuracy score for training set: 0.5677 , 0.5677.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5431 , 0.5431.\n",
      "Training a MLPClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.3152 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.599122165326 0.599122165326\n",
      "F1 score and accuracy score for training set: 0.5991 , 0.5991.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5169 , 0.5169.\n",
      "Training a MLPClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.2764 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.554498902707 0.554498902707\n",
      "F1 score and accuracy score for training set: 0.5545 , 0.5545.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5334 , 0.5334.\n",
      "Training a MLPClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.3015 seconds\n",
      "Made predictions in 0.0156 seconds.\n",
      "0.580102414045 0.580102414045\n",
      "F1 score and accuracy score for training set: 0.5801 , 0.5801.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5065 , 0.5065.\n",
      "Training a MLPClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.3202 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.586686174104 0.586686174104\n",
      "F1 score and accuracy score for training set: 0.5867 , 0.5867.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.4993 , 0.4993.\n",
      "Training a MLPClassifier using a training set size of 2734. . .\n",
      "Trained model in 0.4103 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "0.631309436723 0.631309436723\n",
      "F1 score and accuracy score for training set: 0.6313 , 0.6313.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score and accuracy score for test set: 0.5302 , 0.5302.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the three models (XGBoost is initialized later)\n",
    "clf_LR = LogisticRegression(C=2500, random_state = 42) #LINEAR REGRESSION\n",
    "clf_SVM = SVC(C=2500, random_state = 912, kernel='rbf') #SUPPORT VECTOR MACHINE\n",
    "clf_XGB = xgb.XGBClassifier(seed = 82) #XG-BOOST\n",
    "clf_KNN = neighbors.KNeighborsClassifier(n_neighbors=400, weights='uniform') #K-NEAREST NEIGHBORS\n",
    "clf_RF = RandomForestClassifier(max_depth=3, random_state=0,min_samples_split=40) #RANDOM FOREST\n",
    "clf_ADB = AdaBoostClassifier(base_estimator=None, n_estimators=20, learning_rate=1.0, random_state=0) #ADAPTIVE BOOSTING\n",
    "clf_NB = GaussianNB() #NAIVE BAYES\n",
    "clf_DT = tree.DecisionTreeClassifier(min_samples_split=3) #DECISION TREE\n",
    "clf_NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(9, 2), random_state=1) #MULTY-LAYERED PERCEPTION NEURAL NETWORK\n",
    "\n",
    "#Boosting refers to this general problem of producing a very accurate prediction rule \n",
    "#by combining rough and moderately inaccurate rules-of-thumb\n",
    "\n",
    "train_predict(clf_LR, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_LR, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_LR, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_LR, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_LR, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_LR, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_LR, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n",
    "train_predict(clf_SVM, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_SVM, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_SVM, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_SVM, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_SVM, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_SVM, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_SVM, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n",
    "train_predict(clf_XGB, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_XGB, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_XGB, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_XGB, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_XGB, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_XGB, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_XGB, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n",
    "train_predict(clf_KNN, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_KNN, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_KNN, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_KNN, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_KNN, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_KNN, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_KNN, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n",
    "train_predict(clf_RF, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_RF, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_RF, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_RF, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_RF, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_RF, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_RF, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n",
    "train_predict(clf_ADB, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_ADB, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_ADB, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_ADB, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_ADB, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_ADB, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_ADB, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n",
    "train_predict(clf_NB, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_NB, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_NB, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_NB, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_NB, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_NB, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_NB, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n",
    "train_predict(clf_DT, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_DT, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_DT, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_DT, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_DT, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_DT, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_DT, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n",
    "train_predict(clf_NN, X_all1, y_all1, X_test1, y_test1)\n",
    "train_predict(clf_NN, X_all2, y_all2, X_test2, y_test2)\n",
    "train_predict(clf_NN, X_all3, y_all3, X_test3, y_test3)\n",
    "train_predict(clf_NN, X_all4, y_all4, X_test4, y_test4)\n",
    "train_predict(clf_NN, X_all5, y_all5, X_test5, y_test5)\n",
    "train_predict(clf_NN, X_all6, y_all6, X_test6, y_test6)\n",
    "train_predict(clf_NN, X_allC, y_allC, X_testC, y_testC)\n",
    "print ('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clearly XGBoost seems like the best model as it has the highest F1 score and accuracy score on the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the parameters of XGBoost.\n",
    "\n",
    "![alt text](https://i.stack.imgur.com/9GgQK.jpg \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-26d3b60d6362>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# TODO: Fit the grid search object to the training data and find the optimal parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mgrid_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Get the estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m                 for train, test in cv)\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m         \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m             \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m   1749\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1751\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[1;32m--> 108\u001b[1;33m                                                  **self._kwargs)\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m-> 1040\u001b[1;33m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[0;32m   1041\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "# Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "#parameters = { 'learning_rate' : [0.1],\n",
    "#               'n_estimators' : [40],\n",
    "#               'max_depth': [3],\n",
    "#               'min_child_weight': [3],\n",
    "#               'gamma':[0.4],\n",
    "#               'subsample' : [0.8],\n",
    "#               'colsample_bytree' : [0.8],\n",
    "#               'scale_pos_weight' : [1],\n",
    "#               'reg_alpha':[1e-5]\n",
    "#             }  \n",
    "\n",
    "parameters = { 'tol' : [0.0001],\n",
    "              'C' : [1.0], \n",
    "              'intercept_scaling' : [1], \n",
    "              'max_iter' : [100],\n",
    "              'n_jobs' : [1]\n",
    "             }\n",
    "\n",
    "# Initialize the classifier\n",
    "\n",
    "#clf = xgb.XGBClassifier(seed=2)\n",
    "clf = LogisticRegression(random_state = 2)\n",
    "\n",
    "# TODO: Make an f1 scoring function using 'make_scorer'\n",
    "\n",
    "#f1_scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score,pos_label='W',average='binary')\n",
    "\n",
    "# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf,\n",
    "                        scoring=f1_scorer,\n",
    "                        param_grid=parameters,\n",
    "                        cv=5)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "print (clf)\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "f1, acc = predict_labels(clf, X_train, y_train)\n",
    "print (\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "f1, acc = predict_labels(clf, X_test, y_test)\n",
    "print (\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x0000020674604E80>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Juna\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 368, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-77ea7aabdce3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ma2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'zip' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#clf.predict(X_test[5])\n",
    "print(row[1] for row in X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Improvements?\n",
    "\n",
    "-Adding Sentiment from Twitter, News Articles\n",
    "-More features from other data sources (how much did others bet, player specific health stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
